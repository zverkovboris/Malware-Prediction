

```python
import pickle
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, roc_auc_score
import sys
sys.path.append('../')
from malware_ml.Column_types import dtypes
import gc
gc.enable()
```


```python
categories = list(filter(lambda x : dtypes[x] == 'category', dtypes))
categories.remove('MachineIdentifier')
categories
```

# Обработка категориальных параметров

Дальше рассмотрены 2 подхода к кодированию категориальных параметров: LabelEncoding и хэширование. Я не стал использовать one-hot-encoding так как это сильно бы увеличивало число параметров.

Недостаток LabelEncoding в том, что нам нужно посмотреть обе выборки и закодировать всевозможные категориальные признаки, что очень затратно по ресурсам. Также могут появиться новые значения, которые не были рассмотрены на этапе кодирования.

В хэшировании непонятно пространство какого размера необходимо выбрать чтобы свести коллизии к минимуму.


```python
train = pd.read_csv('../data/train.csv', dtype=dtypes)
test = pd.read_csv('../data/test.csv', dtype=dtypes)
submit = test[['MachineIdentifier']]
train = train.drop('MachineIdentifier', axis=1)
test = test.drop('MachineIdentifier', axis=1)
```

#### Все модели обучаются полностью на тренировочных данных  
Обученная модель проверяется на тестовой выборке и результаты отправляются на kaggle.  
Точность модели оцениваем по Public Score и Private Score на Kaggle. Решения оцениваются по метрике 'roc_auc'.  
Я выбрал данный подход из-за того, что мы можем использовать все данные, которые у нас есть в тренировочной выборке, что дает более хорошее обобщение предсказания.

## Label Encoding  

#### Все сохраненные модели используют хэширование


```python
from sklearn.preprocessing import LabelEncoder
for feature in categories:
    train[feature] = train[feature].astype('str')
    test[feature] = test[feature].astype('str')
    le = LabelEncoder().fit(np.unique(train[feature].unique().tolist() + 
                                    test[feature].unique().tolist()))
    train[feature] = le.transform(train[feature]) + 1
    test[feature] = le.transform(test[feature]) + 1
train.head()
```

## Хэширование


```python
hash_space = 600
for i in categories:
    train[i] = pd.DataFrame(data=[hash(s) % hash_space for s in train[i]])
    test[i] = pd.DataFrame(data=[hash(s) % hash_space for s in test[i]])
train.head()
```


```python
gc.collect()
```

### Нормализация значений


```python
train = train.replace(np.nan, 0)
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0,1))
scaler.fit(train)
train = scaler.transform(train)

test = test.replace(np.nan, 0)
scaler.fit(test)
test = scaler.transform(test)
```

# Logistic regression


```python
from sklearn.linear_model import LogisticRegression
log_reg = LogisticRegression(C=0.0001, solver='sag', max_iter=100)
log_reg.fit(train[:,:-1], train[:,-1])
pkl_filename = '../models/logistic_regression.pkl'
with open(pkl_filename, 'wb') as file:
    pickle.dump(log_reg, file)
predictions = log_reg.predict_proba(test)[:,1]
submit['HasDetections'] = predictions
submit.to_csv('../kaggle_submissions/log_reg.csv', index=False)
```

Public Score 0.62710  
Private Score 0.55644


```python
gc.collect()
```

# Random Forest


```python
from sklearn.ensemble import RandomForestClassifier
random_forest = RandomForestClassifier(n_estimators=100, max_depth=-1)
random_forest.fit(train[:,:-1], train[:,-1])
predictions = random_forest.predict_proba(test)[:,1]
pkl_filename = '../models/random_forest.pkl'
    with open(pkl_filename, 'wb') as file:
        pickle.dump(random_forest, file)
    predictions = random_forest.predict_proba(test)[:,1]
    submit['HasDetections'] = predictions
    submit.to_csv('../kaggle_submissions/random_forest.csv', index=False)
```

Public Score 0.59840  
Private Score 0.52895

# LGBM model


```python
from lightgbm import LGBMClassifier
model = LGBMClassifier(n_estimators=100, max_depth=-1)
model.fit(train[:,:-1], train[:,-1])
gc.collect()
pkl_filename = '../models/lgbm.pkl'
with open(pkl_filename, 'wb') as file:
    pickle.dump(model, file)
predictions = model.predict_proba(test)[:,1]
submit['HasDetections'] = predictions
submit.to_csv('../kaggle_submissions/lgbm.csv', index=False)
gc.collect()
```

Public Score 0.66224  
Private Score 0.62423
