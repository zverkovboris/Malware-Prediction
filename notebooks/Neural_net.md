
# Обучение классификатора с помощью нейронной сети


```python
import pickle
import numpy as np
import pandas as pd
from Column_types import dtypes
import sys
sys.path.append('../')
from malware_ml.neural_net_metrics import f1, precision, recall
import gc
gc.enable()
```


```python
categories = list(filter(lambda x : dtypes[x] == 'category', dtypes))
categories.remove('MachineIdentifier')
categories
```


```python
train = pd.read_csv('../data/train.csv', dtype=dtypes)
test = pd.read_csv('../data/test.csv', dtype=dtypes)
hash_space = 600
train = train.drop('MachineIdentifier', axis=1)
print(train.head())
submit = test[['MachineIdentifier']]
test = test.drop('MachineIdentifier', axis=1)
for i in categories:
    train[i] = pd.DataFrame(data=[hash(s) % hash_space for s in train[i]])
    test[i] = pd.DataFrame(data=[hash(s) % hash_space for s in test[i]])
train.head()
```

Для ускорения обучения возьмем некоторую часть от наших данных. Для валидации возьмем 1000000 из них.


```python
gc.collect()
train = train.sample(n=4000000, random_state=1)
gc.collect()
```


```python
from sklearn.preprocessing import MinMaxScaler
train = train.replace(np.nan, 0)
test = test.replace(np.nan, 0)
scaler = MinMaxScaler(feature_range=(0,1))
scaler.fit(train)
train = scaler.transform(train)
gc.collect()
scaler.fit(test)
test = scaler.transform(test)
gc.collect()
```

Добавим свои метрики для оценки качества обучения, помимо precision, recall, f-score


```python
from keras import callbacks
from sklearn.metrics import roc_auc_score

class printAUC(callbacks.Callback):
    def __init__(self, X_train, y_train):
        super(printAUC, self).__init__()
        self.bestAUC = 0
        self.X_train = X_train
        self.y_train = y_train
        
    def on_epoch_end(self, epoch, logs={}):
        pred = self.model.predict(np.array(self.X_train))
        auc = roc_auc_score(self.y_train, pred)
        print("Train AUC: " + str(auc))
        pred = self.model.predict(self.validation_data[0])
        auc = roc_auc_score(self.validation_data[1], pred)
        print ("Validation AUC: " + str(auc))
        if (self.bestAUC < auc) :
            self.bestAUC = auc
            self.model.save("../models/bestNet.h5", overwrite=True)
        return
```


```python
gc.collect()
```

Сохраняем лучшиие модели по F-score и roc_auc_score


```python
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Dropout, BatchNormalization, Activation
from keras.callbacks import LearningRateScheduler, ModelCheckpoint
from keras.optimizers import Adam

X_train, X_val, Y_train, Y_val = train_test_split(
    train[:,:-1], train[:,-1], test_size = 0.25)
print('start', X_val.shape)
gc.collect()
# BUILD MODEL
model = Sequential()
model.add(Dense(100,input_dim=len(train[1])-1))
model.add(Dropout(0.4))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dense(100))
model.add(Dropout(0.4))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer=Adam(lr=0.01), loss="binary_crossentropy", metrics=[precision, recall, f1])
annealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)
checkpoint = ModelCheckpoint("../models/neural_net-{epoch:02d}-{val_f1:.2f}.hdf5",
                             monitor='val_f1', save_best_only=True, mode='max', period=1)
# TRAIN MODEL
model.fit(X_train,Y_train, batch_size=32, epochs = 20, callbacks=[annealer,
          printAUC(X_train, Y_train), checkpoint], validation_data = (X_val,Y_val), verbose=2)
```

### Также обучим нейронную связь с дополнительным скрытым слоем из 100 нейронов

start (1000000, 81)

Train on 3000000 samples, validate on 1000000 samples
Epoch 1/20
 - 599s - loss: 0.6527 - precision: 0.6221 - recall: 0.5851 - f1: 0.5910 - val_loss: 0.6441 - val_precision: 0.6650 - val_recall: 0.4673 - val_f1: 0.5396
Train AUC: 0.6767451786199312
Validation AUC: 0.676526486320706
Epoch 2/20
 - 599s - loss: 0.6492 - precision: 0.6257 - recall: 0.5985 - f1: 0.6004 - val_loss: 0.6426 - val_precision: 0.6302 - val_recall: 0.6096 - val_f1: 0.6121
Train AUC: 0.6793018044491563
Validation AUC: 0.6791918503305642
Epoch 3/20
 - 591s - loss: 0.6484 - precision: 0.6271 - recall: 0.5977 - f1: 0.6009 - val_loss: 0.6384 - val_precision: 0.6337 - val_recall: 0.5979 - val_f1: 0.6075
Train AUC: 0.680759187552143
Validation AUC: 0.6806265805344955
Epoch 4/20
 - 583s - loss: 0.6478 - precision: 0.6273 - recall: 0.6021 - f1: 0.6032 - val_loss: 0.6411 - val_precision: 0.6772 - val_recall: 0.4467 - val_f1: 0.5287
Train AUC: 0.6808371050078063
Validation AUC: 0.6806119312239017
Epoch 5/20
 - 589s - loss: 0.6473 - precision: 0.6290 - recall: 0.5988 - f1: 0.6021 - val_loss: 0.6464 - val_precision: 0.6858 - val_recall: 0.4309 - val_f1: 0.5195
Train AUC: 0.6831756451177128
Validation AUC: 0.6833287812079059
Epoch 6/20
 - 591s - loss: 0.6469 - precision: 0.6291 - recall: 0.6011 - f1: 0.6036 - val_loss: 0.6396 - val_precision: 0.6354 - val_recall: 0.6026 - val_f1: 0.6108
Train AUC: 0.6831830013213082
Validation AUC: 0.6832567866593283
Epoch 7/20
 - 586s - loss: 0.6465 - precision: 0.6298 - recall: 0.6003 - f1: 0.6035 - val_loss: 0.6410 - val_precision: 0.6661 - val_recall: 0.4941 - val_f1: 0.5584
Train AUC: 0.6832057042247829
Validation AUC: 0.6832223804305385
Epoch 8/20
 - 590s - loss: 0.6463 - precision: 0.6303 - recall: 0.6014 - f1: 0.6041 - val_loss: 0.6361 - val_precision: 0.6380 - val_recall: 0.5951 - val_f1: 0.6080
Train AUC: 0.6834478896491816
Validation AUC: 0.6832891771514858
Epoch 9/20
 - 590s - loss: 0.6460 - precision: 0.6301 - recall: 0.6028 - f1: 0.6049 - val_loss: 0.6361 - val_precision: 0.6271 - val_recall: 0.6347 - val_f1: 0.6235
Train AUC: 0.684016332792304
Validation AUC: 0.683948287544183
Epoch 10/20
 - 593s - loss: 0.6459 - precision: 0.6302 - recall: 0.6023 - f1: 0.6046 - val_loss: 0.6355 - val_precision: 0.6520 - val_recall: 0.5487 - val_f1: 0.5876
Train AUC: 0.6852803837152979
Validation AUC: 0.685248985956082
Epoch 11/20
 - 594s - loss: 0.6456 - precision: 0.6303 - recall: 0.6031 - f1: 0.6052 - val_loss: 0.6376 - val_precision: 0.6398 - val_recall: 0.5895 - val_f1: 0.6057
Train AUC: 0.6847385267197882
Validation AUC: 0.6847240730094692
Epoch 12/20
 - 592s - loss: 0.6454 - precision: 0.6310 - recall: 0.6014 - f1: 0.6047 - val_loss: 0.6361 - val_precision: 0.6362 - val_recall: 0.6059 - val_f1: 0.6130
Train AUC: 0.6849768527502718
Validation AUC: 0.6848820183530009
Epoch 13/20
 - 594s - loss: 0.6452 - precision: 0.6316 - recall: 0.6023 - f1: 0.6055 - val_loss: 0.6349 - val_precision: 0.6408 - val_recall: 0.5930 - val_f1: 0.6081
Train AUC: 0.6855769988734118
Validation AUC: 0.6854856993043155
Epoch 14/20
 - 601s - loss: 0.6451 - precision: 0.6315 - recall: 0.6032 - f1: 0.6060 - val_loss: 0.6350 - val_precision: 0.6453 - val_recall: 0.5741 - val_f1: 0.5996
Train AUC: 0.6857348619754754
Validation AUC: 0.6856818255798206
Epoch 15/20
 - 597s - loss: 0.6447 - precision: 0.6313 - recall: 0.6030 - f1: 0.6059 - val_loss: 0.6343 - val_precision: 0.6331 - val_recall: 0.6206 - val_f1: 0.6192
Train AUC: 0.685775282350914
Validation AUC: 0.6857858038504282
Epoch 16/20
 - 598s - loss: 0.6447 - precision: 0.6320 - recall: 0.6027 - f1: 0.6062 - val_loss: 0.6341 - val_precision: 0.6348 - val_recall: 0.6154 - val_f1: 0.6174
Train AUC: 0.6860227965579463
Validation AUC: 0.6859977283048877
Epoch 17/20
 - 591s - loss: 0.6444 - precision: 0.6320 - recall: 0.6028 - f1: 0.6063 - val_loss: 0.6354 - val_precision: 0.6458 - val_recall: 0.5747 - val_f1: 0.6001
Train AUC: 0.6858127108122465
Validation AUC: 0.6856753673117951
Epoch 18/20
 - 593s - loss: 0.6446 - precision: 0.6317 - recall: 0.6036 - f1: 0.6066 - val_loss: 0.6380 - val_precision: 0.6613 - val_recall: 0.5171 - val_f1: 0.5716
Train AUC: 0.6856611362364066
Validation AUC: 0.6855609740859215
Epoch 19/20
 - 596s - loss: 0.6442 - precision: 0.6325 - recall: 0.6028 - f1: 0.6066 - val_loss: 0.6352 - val_precision: 0.6299 - val_recall: 0.6336 - val_f1: 0.6244
Train AUC: 0.6859998842742417
Validation AUC: 0.6859323816363948
Epoch 20/20
 - 594s - loss: 0.6442 - precision: 0.6323 - recall: 0.6025 - f1: 0.6063 - val_loss: 0.6345 - val_precision: 0.6418 - val_recall: 0.5893 - val_f1: 0.6065
Train AUC: 0.6859831877538702
Validation AUC: 0.6859323981844001

<keras.callbacks.History at 0x7f904a115438>


```python
gc.collect()
```


```python
from keras import models
m = models.load_model('../models/neural_net-07-0.65.hdf5', custom_objects={'precision': precision, 'recall': recall, 'f1': f1})
m.compile(optimizer=Adam(lr=0.01), loss="binary_crossentropy", metrics=[precision, recall, f1])
pred = m.predict(test)
submit['HasDetections'] = pd.DataFrame(data=pred)
submit.head()
submit.to_csv('../kaggle_submissions/best_fscore.csv', index=False)
```

Public Score 0.63935  
Private Score 0.56018


```python
from keras import models
m = models.load_model('../models/bestNet.h5', custom_objects={'precision': precision, 'recall': recall, 'f1': f1})
m.compile(optimizer=Adam(lr=0.01), loss="binary_crossentropy", metrics=[precision, recall, f1])
pred = m.predict(test)
submit['HasDetections'] = pd.DataFrame(data=pred)
submit.head()
submit.to_csv('../kaggle_submission/best_roc.csv', index=False)
```

Public Score 0.64328  
Private Score 0.57238


```python
gc.collect()
```

### Для нейронной сети с дополнительным скрытым слоем из 100 нейронов
* Нейронная сеть с лучшим предсказанием по метрике fscore (./models/neural_net-dense-20-0.64.hdf5)  
    Public Score 0.63826  
    Private Score 0.64025  
    
    
* Нейронная сеть с лучшим предсказанием по метрике roc_auc (./models/bestNet-dense.h5)  
    Public Score 0.63758  
    Private Score 0.64133  


```python

```
